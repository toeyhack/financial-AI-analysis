# Lastest worked 
# Support THAI text
import streamlit as st
import pandas as pd
from prophet import Prophet
import xgboost as xgb
import ollama
import openai # For OpenAI GPT API
from google.generativeai import GenerativeModel # For Google Gemini API
from google.generativeai.types import HarmCategory, HarmBlockThreshold # For safety settings
import matplotlib.pyplot as plt
import seaborn as sns
import io
import matplotlib.font_manager as fm # For Thai font handling
import os # For checking file existence
import requests # For downloading font

# --- Thai Font Configuration for Matplotlib ---
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î URL ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ü‡∏≠‡∏ô‡∏ï‡πå
font_url = "https://github.com/google/fonts/raw/main/ofl/kanit/Kanit-Regular.ttf"
font_filename = "Kanit-Regular.ttf"
# ‡πÉ‡∏ä‡πâ os.path.join ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ path ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏ô‡∏ó‡∏∏‡∏Å OS
font_path = os.path.join(os.getcwd(), font_filename) 

st.sidebar.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Font ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢")

# ‡πÉ‡∏ä‡πâ st.cache_resource ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
@st.cache_resource(ttl=3600 * 24 * 7) # Cache for 1 week
def download_font_once(url, filename, path):
    if not os.path.exists(path):
        st.sidebar.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå {filename}...")
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status() # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ request ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
            with open(path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            st.sidebar.success(f"‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {filename} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")
            return True
        except requests.exceptions.RequestException as e:
            st.sidebar.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î {filename} ‡πÑ‡∏î‡πâ: {e}. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï.")
            return False
    else:
        st.sidebar.info(f"‡∏ü‡∏≠‡∏ô‡∏ï‡πå {filename} ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß.")
        return True

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
font_downloaded = download_font_once(font_url, font_filename, font_path)

thai_font_name = "Kanit" # ‡∏ä‡∏∑‡πà‡∏≠ Font Family ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

if font_downloaded:
    try:
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏•‡∏á‡πÉ‡∏ô Matplotlib font manager
        # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å Matplotlib ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà
        fm.fontManager.addfont(font_path)
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ Matplotlib ‡πÉ‡∏ä‡πâ‡∏ü‡∏≠‡∏ô‡∏ï‡πå Kanit ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        plt.rcParams['font.family'] = thai_font_name
        plt.rcParams['font.size'] = 12
        plt.rcParams['axes.unicode_minus'] = False # ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏•‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á
        # fm.findfont ‡∏à‡∏∞ return path ‡∏Ç‡∏≠‡∏á font ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö, ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ä‡∏∑‡πà‡∏≠ font
        if fm.findfont(thai_font_name, fontext='ttf'):
            kanit_font_prop = fm.FontProperties(fname=font_path)
            st.sidebar.success(f"‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå '{thai_font_name}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! (‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà Matplotlib ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å: '{kanit_font_prop.get_name()}')")
        else:
            st.sidebar.warning(f"Font '{thai_font_name}' ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡πÇ‡∏î‡∏¢ Matplotlib. ‡∏≠‡∏≤‡∏à‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á.")
            st.sidebar.info("‡πÉ‡∏ä‡πâ Font ‡∏™‡∏≥‡∏£‡∏≠‡∏á 'DejaVu Sans'.")
            plt.rcParams['font.family'] = 'DejaVu Sans' # Fallback
            plt.rcParams['font.size'] = 12
            plt.rcParams['axes.unicode_minus'] = False
            kanit_font_prop = None # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
        
    except Exception as e:
        st.sidebar.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Font '{thai_font_name}': {e}. ‡πÉ‡∏ä‡πâ Font ‡∏™‡∏≥‡∏£‡∏≠‡∏á 'DejaVu Sans'.")
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['font.size'] = 12
        plt.rcParams['axes.unicode_minus'] = False
        kanit_font_prop = None # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
else:
    st.sidebar.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå '{thai_font_name}' ‡πÑ‡∏î‡πâ. ‡πÉ‡∏ä‡πâ Font ‡∏™‡∏≥‡∏£‡∏≠‡∏á 'DejaVu Sans'.")
    plt.rcParams['font.family'] = 'DejaVu Sans'
    plt.rcParams['font.size'] = 12
    plt.rcParams['axes.unicode_minus'] = False
    kanit_font_prop = None # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î

# ... ‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (st.set_page_config ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô ‡πÜ) ...
# --- Streamlit Page Configuration ---
st.set_page_config(layout="wide", page_title="Real Estate Sales AI Assistant")

st.title("üè° Sales AI Assistant")
st.write("‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏£‡∏¥‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏î‡πâ‡∏ß‡∏¢ AI")

# --- Sidebar for Settings and Data Folder Path ---
st.sidebar.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

# NEW: AI Model Provider Selection
ai_provider = st.sidebar.selectbox(
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å AI Model Provider:",
    ["Ollama (Local Llama)", "OpenAI (GPT)", "Google AI (Gemini)"]
)

if ai_provider == "Ollama (Local Llama)":
    ollama_base_url = st.sidebar.text_input(
        "URL ‡∏Ç‡∏≠‡∏á Ollama Server:",
        "http://10.10.32.78:11434" # Default value
    )
    ollama_model_name = st.sidebar.text_input(
        "‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• Ollama (‡πÄ‡∏ä‡πà‡∏ô llama3.1:8b):",
        "llama3.1:8b" # Default value
    )
    # Set default values for other providers to avoid errors later
    openai_api_key = None
    openai_model_name = None
    google_api_key = None
    google_model_name = None

elif ai_provider == "OpenAI (GPT)":
    openai_api_key = st.sidebar.text_input("OpenAI API Key:", type="password")
    openai_model_name = st.sidebar.text_input(
        "‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• OpenAI (‡πÄ‡∏ä‡πà‡∏ô gpt-3.5-turbo, gpt-4o):",
        "gpt-4o" # Default to a capable model
    )
    # Set default values for other providers
    ollama_base_url = None
    ollama_model_name = None
    google_api_key = None
    google_model_name = None

elif ai_provider == "Google AI (Gemini)":
    google_api_key = st.sidebar.text_input("Google AI API Key:", type="password")
    google_model_name = st.sidebar.text_input(
        "‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• Google Gemini (‡πÄ‡∏ä‡πà‡∏ô gemini-pro, gemini-1.5-flash):",
        "gemini-1.5-flash" # Default to a capable model
    )
    # Set default values for other providers
    ollama_base_url = None
    ollama_model_name = None
    openai_api_key = None
    openai_model_name = None

# Data folder path input (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
data_folder = st.sidebar.text_input(
    "‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ä‡πà‡∏ô data/ ‡∏´‡∏£‡∏∑‡∏≠ /path/to/data/):",
    "data/" # Default value
)


# --- Data Loading & Preprocessing Functions ---

# Helper function to check file existence
def check_file_exists(file_path):
    if not os.path.exists(file_path):
        st.sidebar.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {file_path}. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á.")
        return False
    return True

@st.cache_data
def load_and_preprocess_sales_data(file_path):
    """Loads and preprocesses the main sales data."""
    if not check_file_exists(file_path):
        return pd.DataFrame()
    try:
        df = pd.read_csv(file_path)
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df = df.dropna(subset=['Date']).sort_values(by='Date') # Drop rows with invalid dates
        df['Units_Sold'] = pd.to_numeric(df['Units_Sold'], errors='coerce').fillna(0)
        df['Sales_Revenue'] = pd.to_numeric(df['Sales_Revenue'], errors='coerce').fillna(0)

        # Feature Engineering for sales_df itself (before merge)
        df['month'] = df['Date'].dt.month
        df['day_of_week'] = df['Date'].dt.dayofweek
        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
        
        # Lag features (ensure Project_ID is present for groupby)
        if 'Project_ID' in df.columns:
            df['sales_lag_7'] = df.groupby('Project_ID')['Units_Sold'].shift(7).fillna(0)
            df['sales_lag_30'] = df.groupby('Project_ID')['Units_Sold'].shift(30).fillna(0)
        else:
            df['sales_lag_7'] = 0
            df['sales_lag_30'] = 0

        # Convert categorical features from sales_history to numerical (if they exist)
        for col_name in ['Promotion_Applied', 'Lead_Source', 'Marketing_Channel']:
            if col_name in df.columns:
                df[f'{col_name}_encoded'] = df[col_name].astype('category').cat.codes
            else:
                df[f'{col_name}_encoded'] = 0 # Default if column is missing

        # Fill NaNs for numeric columns expected from sales_history.csv for XGBoost
        numeric_cols_from_sales = [
            'Avg_Competitor_Price_Nearby', 'Interest_Rate_Change_Indicator',
            'Nearby_Infrastructure_Dev_Score', 'Economic_Sentiment_Index'
        ]
        for col in numeric_cols_from_sales:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(df[col].mean() if not df[col].isnull().all() else 0)
            else:
                df[col] = 0 # Create and fill with 0 if missing in the uploaded CSV

        st.sidebar.success("‡πÇ‡∏´‡∏•‡∏î sales_history.csv ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß")
        return df
    except Exception as e:
        st.sidebar.error(f"Error loading or preprocessing Sales History file from {file_path}: {e}")
        st.exception(e)
        return pd.DataFrame()

@st.cache_data
def load_project_details(file_path):
    """Loads and preprocesses project details data."""
    if not check_file_exists(file_path):
        return pd.DataFrame()
    try:
        df = pd.read_csv(file_path)
        df['Total_Units'] = pd.to_numeric(df['Total_Units'], errors='coerce').fillna(0)
        df['Units_Completed'] = pd.to_numeric(df['Units_Completed'], errors='coerce').fillna(0)
        df['Units_Sold_toDate'] = pd.to_numeric(df['Units_Sold_toDate'], errors='coerce').fillna(0)
        df['Proximity_to_BTS_MRT_Km'] = pd.to_numeric(df['Proximity_to_BTS_MRT_Km'], errors='coerce').fillna(df['Proximity_to_BTS_MRT_Km'].mean() if not df['Proximity_to_BTS_MRT_Km'].isnull().all() else 0)
        for col in ['Land_Cost_Per_SqM', 'Construction_Cost_Per_SqM', 'Average_Selling_Price_Per_SqM_Initial',
                    'Amenities_Score', 'Green_Space_Ratio', 'Parking_Ratio', 'Marketing_Budget_Initial']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(df[col].mean() if not df[col].isnull().all() else 0)
            else:
                df[col] = 0
        st.sidebar.success("‡πÇ‡∏´‡∏•‡∏î project_details.csv ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß")
        return df
    except Exception as e:
        st.sidebar.error(f"Error loading or preprocessing Project Details file from {file_path}: {e}")
        st.exception(e)
        return pd.DataFrame()

@st.cache_data
def load_macro_economic_data(file_path):
    """Loads and preprocesses macroeconomic data."""
    if not check_file_exists(file_path):
        return pd.DataFrame()
    try:
        df = pd.read_csv(file_path)
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df = df.dropna(subset=['Date']).sort_values(by='Date') # Drop rows with invalid dates
        numeric_cols = ['Interest_Rate_Percent', 'Inflation_Rate_Percent', 'GDP_Growth_Rate_Percent',
                        'Consumer_Confidence_Index', 'Unemployment_Rate_Percent',
                        'Foreign_Investment_Index', 'Housing_Price_Index_Nationwide']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(df[col].mean() if not df[col].isnull().all() else 0)
            else:
                df[col] = 0 # Create and fill with 0 if missing
        st.sidebar.success("‡πÇ‡∏´‡∏•‡∏î macro_economic_data.csv ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß")
        return df
    except Exception as e:
        st.sidebar.error(f"Error loading or preprocessing Macroeconomic Indicators file from {file_path}: {e}")
        st.exception(e)
        return pd.DataFrame()

@st.cache_data
def load_marketing_activities(file_path):
    """Loads and preprocesses marketing activities data."""
    if not check_file_exists(file_path):
        return pd.DataFrame()
    try:
        df = pd.read_csv(file_path)
        df['Activity_Date'] = pd.to_datetime(df['Activity_Date'], errors='coerce')
        df = df.dropna(subset=['Activity_Date']).sort_values(by='Activity_Date')
        df['Budget_Baht'] = pd.to_numeric(df['Budget_Baht'], errors='coerce').fillna(0)
        df['Leads_Generated'] = pd.to_numeric(df['Leads_Generated'], errors='coerce').fillna(0)
        st.sidebar.success("‡πÇ‡∏´‡∏•‡∏î marketing_activities.csv ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß")
        return df
    except Exception as e:
        st.sidebar.error(f"Error loading or preprocessing Marketing Activities file from {file_path}: {e}")
        st.exception(e)
        return pd.DataFrame()

@st.cache_data
def load_sales_funnel_log(file_path):
    """Loads and preprocesses sales funnel log data."""
    if not check_file_exists(file_path):
        return pd.DataFrame()
    try:
        df = pd.read_csv(file_path)
        df['Lead_Date'] = pd.to_datetime(df['Lead_Date'], errors='coerce')
        df['Status_Change_Date'] = pd.to_datetime(df['Status_Change_Date'], errors='coerce')
        df = df.dropna(subset=['Lead_Date'])
        df['Is_Converted_to_Sale'] = df['Is_Converted_to_Sale'].astype(bool)
        st.sidebar.success("‡πÇ‡∏´‡∏•‡∏î sales_funnel_log.csv ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß")
        return df
    except Exception as e:
        st.sidebar.error(f"Error loading or preprocessing Sales Funnel Log file from {file_path}: {e}")
        st.exception(e)
        return pd.DataFrame()

@st.cache_data
def load_competitor_data(file_path):
    """Loads and preprocesses competitor data."""
    if not check_file_exists(file_path):
        return pd.DataFrame()
    try:
        df = pd.read_csv(file_path)
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df = df.dropna(subset=['Date']).sort_values(by='Date')
        df['Avg_Price_Per_SqM'] = pd.to_numeric(df['Avg_Price_Per_SqM'], errors='coerce').fillna(df['Avg_Price_Per_SqM'].mean() if not df['Avg_Price_Per_SqM'].isnull().all() else 0)
        df['Sales_Volume_Estimate'] = pd.to_numeric(df['Sales_Volume_Estimate'], errors='coerce').fillna(0)
        st.sidebar.success("‡πÇ‡∏´‡∏•‡∏î competitor_analysis.csv ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß")
        return df
    except Exception as e:
        st.sidebar.error(f"Error loading or preprocessing Competitor Data file from {file_path}: {e}")
        st.exception(e)
        return pd.DataFrame()

@st.cache_data
def load_and_preprocess_feedback_data(file_path):
    """Loads and preprocesses customer feedback data."""
    if not check_file_exists(file_path):
        return pd.DataFrame()
    try:
        df = pd.read_csv(file_path)
        if 'feedback_text' not in df.columns:
            st.warning("Column 'feedback_text' not found in feedback data. Skipping feedback analysis.")
            return pd.DataFrame() # Return empty if essential column is missing
        st.sidebar.success("‡πÇ‡∏´‡∏•‡∏î customer_feedback.csv ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß")
        return df
    except Exception as e:
        st.sidebar.error(f"Error loading or preprocessing Customer Feedback file from {file_path}: {e}")
        st.exception(e)
        return pd.DataFrame()


# --- Load all DataFrames from specified folder ---
st.sidebar.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå")

sales_df = load_and_preprocess_sales_data(os.path.join(data_folder, 'sales_history.csv'))
project_details_df = load_project_details(os.path.join(data_folder, 'project_details.csv'))
macro_economic_df = load_macro_economic_data(os.path.join(data_folder, 'macro_economic_data.csv'))
marketing_activities_df = load_marketing_activities(os.path.join(data_folder, 'marketing_activities.csv'))
sales_funnel_df = load_sales_funnel_log(os.path.join(data_folder, 'sales_funnel_log.csv'))
competitor_df = load_competitor_data(os.path.join(data_folder, 'competitor_analysis.csv'))
feedback_df = load_and_preprocess_feedback_data(os.path.join(data_folder, 'customer_feedback.csv'))


# --- Data Merging Section ---
st.subheader("üîÑ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Merging Status)")

# 1. Merge Project Details into sales_df
if not sales_df.empty and not project_details_df.empty:
    st.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏£‡∏ß‡∏° Sales Data ‡∏Å‡∏±‡∏ö Project Details...")
    sales_df['Project_ID'] = sales_df['Project_ID'].astype(str)
    project_details_df['Project_ID'] = project_details_df['Project_ID'].astype(str)

    sales_df = pd.merge(sales_df, project_details_df, on='Project_ID', how='left')

    project_cols_expected = [
        'Project_Type', 'Location_District', 'Target_Audience', 'Project_Status',
        'Total_Units', 'Units_Completed', 'Units_Sold_toDate', 'Project_Size_Acres',
        'Proximity_to_BTS_MRT_Km', 'Proximity_to_Shopping_Km', 'Proximity_to_School_Km',
        'Land_Cost_Per_SqM', 'Construction_Cost_Per_SqM', 'Average_Selling_Price_Per_SqM_Initial',
        'Amenities_Score', 'Green_Space_Ratio', 'Parking_Ratio', 'Marketing_Budget_Initial'
    ]
    for col in project_cols_expected:
        if col not in sales_df.columns:
            if col in ['Project_Type', 'Location_District', 'Target_Audience', 'Project_Status']:
                sales_df[col] = 'Unknown'
            else:
                sales_df[col] = 0
        else:
            if sales_df[col].dtype == 'object':
                sales_df[col] = sales_df[col].fillna('Unknown')
            else:
                sales_df[col] = sales_df[col].fillna(0)

    st.success("‡∏£‡∏ß‡∏° Project Details ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö Sales Data ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô.")
    st.dataframe(sales_df[['Project_ID', 'Project_Type', 'Total_Units', 'Proximity_to_BTS_MRT_Km']].head())
else:
    st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏ß‡∏° Project Details ‡πÑ‡∏î‡πâ: Sales Data ‡∏´‡∏£‡∏∑‡∏≠ Project Details ‡∏¢‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤. ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå.")
    for col in ['Project_Type', 'Total_Units', 'Proximity_to_BTS_MRT_Km', 'Amenities_Score', 'Marketing_Budget_Initial']:
        if col not in sales_df.columns:
            if col == 'Project_Type':
                sales_df[col] = 'Unknown'
            else:
                sales_df[col] = 0

# 2. Merge Macro Economic Data into sales_df
if not sales_df.empty and not macro_economic_df.empty:
    st.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏£‡∏ß‡∏° Sales Data ‡∏Å‡∏±‡∏ö Macroeconomic Data...")
    sales_df['Date_Month'] = sales_df['Date'].dt.to_period('M').dt.to_timestamp('M')
    macro_economic_df['Date_Month'] = macro_economic_df['Date'].dt.to_period('M').dt.to_timestamp('M')

    sales_df = pd.merge(sales_df, macro_economic_df.drop(columns=['Date']), on='Date_Month', how='left')
    sales_df.drop(columns=['Date_Month'], inplace=True) # Drop the temporary merge column

    macro_cols_expected = [
        'Interest_Rate_Percent', 'Inflation_Rate_Percent', 'GDP_Growth_Rate_Percent',
        'Consumer_Confidence_Index', 'Unemployment_Rate_Percent',
        'Foreign_Investment_Index', 'Housing_Price_Index_Nationwide'
    ]
    for col in macro_cols_expected:
        if col not in sales_df.columns:
            sales_df[col] = 0
        else:
            sales_df[col] = sales_df[col].fillna(0)

    st.success("‡∏£‡∏ß‡∏° Macroeconomic Data ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö Sales Data ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô.")
    st.dataframe(sales_df[['Date', 'Interest_Rate_Percent', 'Consumer_Confidence_Index']].head())
else:
    st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏ß‡∏° Macroeconomic Data ‡πÑ‡∏î‡πâ: Sales Data ‡∏´‡∏£‡∏∑‡∏≠ Macroeconomic Data ‡∏¢‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤. ‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£.")
    for col in ['Interest_Rate_Percent', 'Inflation_Rate_Percent', 'GDP_Growth_Rate_Percent', 'Consumer_Confidence_Index']:
        if col not in sales_df.columns:
            sales_df[col] = 0

st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢ (Sales Data) ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
if not sales_df.empty:
    st.dataframe(sales_df.head())
    st.write(f"Sales Data ‡∏°‡∏µ {len(sales_df)} ‡πÅ‡∏ñ‡∏ß ‡πÅ‡∏•‡∏∞ {len(sales_df.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå.")
    st.write("‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:", sales_df.columns.tolist())
else:
    st.error("Sales Data ‡∏¢‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV.")

# --- Sales Forecasting Section (Moved after all merges) ---
st.header("üìä ‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢")
if not sales_df.empty:
    st.write("‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Prophet + XGBoost")

    prophet_df = sales_df.groupby('Date')['Units_Sold'].sum().reset_index()
    prophet_df.rename(columns={'Date': 'ds', 'Units_Sold': 'y'}, inplace=True)

    if len(prophet_df) > 1: # Prophet needs at least 2 data points
        try:
            m = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)
            m.fit(prophet_df)

            future_periods = st.slider("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå:", 7, 90, 30)
            future = m.make_future_dataframe(periods=future_periods)
            forecast_prophet = m.predict(future)

            daily_sales_features = sales_df.groupby('Date').agg({
                'month': 'first',
                'day_of_week': 'first',
                'is_weekend': 'first',
                'sales_lag_7': 'sum',
                'sales_lag_30': 'sum',
                'Avg_Competitor_Price_Nearby': 'mean',
                'Interest_Rate_Change_Indicator': 'mean',
                'Nearby_Infrastructure_Dev_Score': 'mean',
                'Economic_Sentiment_Index': 'mean',
                'Total_Units': 'sum', # From Project Details
                'Proximity_to_BTS_MRT_Km': 'mean', # From Project Details
                'Amenities_Score': 'mean', # From Project Details
                'Marketing_Budget_Initial': 'sum', # From Project Details
                'Inflation_Rate_Percent': 'mean', # From Macro Economic
                'GDP_Growth_Rate_Percent': 'mean', # From Macro Economic
                'Consumer_Confidence_Index': 'mean', # From Macro Economic
                'Units_Sold': 'sum' # Actual sales for training residuals
            }).reset_index()

            daily_sales_features = daily_sales_features.merge(
                forecast_prophet[['ds', 'yhat']],
                left_on='Date', right_on='ds', how='left'
            )
            daily_sales_features['prophet_yhat'] = daily_sales_features['yhat']
            daily_sales_features['residuals'] = daily_sales_features['Units_Sold'] - daily_sales_features['prophet_yhat']

            xgb_features = [
                'month', 'day_of_week', 'is_weekend',
                'sales_lag_7', 'sales_lag_30',
                'Avg_Competitor_Price_Nearby', 'Interest_Rate_Change_Indicator',
                'Nearby_Infrastructure_Dev_Score', 'Economic_Sentiment_Index',
                'Total_Units', 'Proximity_to_BTS_MRT_Km', 'Amenities_Score', 'Marketing_Budget_Initial',
                'Inflation_Rate_Percent', 'GDP_Growth_Rate_Percent', 'Consumer_Confidence_Index'
            ]
            xgb_features_existing = [col for col in xgb_features if col in daily_sales_features.columns]
            if len(xgb_features_existing) != len(xgb_features):
                st.warning(f"‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Feature ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost ‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô: {list(set(xgb_features) - set(xgb_features_existing))}. ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏≤‡∏à‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö.")
            
            for col in xgb_features_existing:
                daily_sales_features[col] = pd.to_numeric(daily_sales_features[col], errors='coerce').fillna(daily_sales_features[col].mean() if not daily_sales_features[col].isnull().all() else 0)


            train_df_xgb = daily_sales_features.dropna(subset=['Units_Sold', 'residuals'] + xgb_features_existing)

            if not train_df_xgb.empty and len(train_df_xgb) > 1 and all(col in train_df_xgb.columns for col in xgb_features_existing):
                X_train_xgb = train_df_xgb[xgb_features_existing]
                y_train_xgb = train_df_xgb['residuals']

                xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
                xgb_model.fit(X_train_xgb, y_train_xgb)

                future_xgb_df = future.copy()
                future_xgb_df['month'] = future_xgb_df['ds'].dt.month
                future_xgb_df['day_of_week'] = future_xgb_df['ds'].dt.dayofweek
                future_xgb_df['is_weekend'] = future_xgb_df['day_of_week'].isin([5, 6]).astype(int)
                
                for col in xgb_features_existing:
                    if col not in ['month', 'day_of_week', 'is_weekend']:
                        if col in train_df_xgb.columns and not train_df_xgb[col].empty:
                            future_xgb_df[col] = train_df_xgb[col].iloc[-1]
                        else:
                            future_xgb_df[col] = 0

                for col in xgb_features_existing:
                    future_xgb_df[col] = pd.to_numeric(future_xgb_df[col], errors='coerce').fillna(0)

                xgb_residual_pred = xgb_model.predict(future_xgb_df[xgb_features_existing])

                final_forecast_df = forecast_prophet.copy()
                final_forecast_df['xgb_residual_pred'] = xgb_residual_pred
                final_forecast_df['yhat_hybrid'] = final_forecast_df['yhat'] + final_forecast_df['xgb_residual_pred']
                final_forecast_df['yhat_hybrid'] = final_forecast_df['yhat_hybrid'].apply(lambda x: max(0, round(x)))

                st.subheader("‡∏Å‡∏£‡∏≤‡∏ü‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°")
                fig = plt.figure(figsize=(12, 6))
                plt.plot(prophet_df['ds'], prophet_df['y'], label='‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á‡∏£‡∏ß‡∏°', color='blue')
                plt.plot(final_forecast_df['ds'], final_forecast_df['yhat_hybrid'], label='‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (Prophet + XGBoost)', color='green', linestyle='--')
                plt.plot(forecast_prophet['ds'], forecast_prophet['yhat'], label='‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (Prophet Baseline)', color='orange', linestyle=':')
                
                forecast_start_date = sales_df['Date'].max()
                plt.axvline(x=forecast_start_date, color='red', linestyle='--', label='‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå', alpha=0.7)

                plt.title('‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏£‡∏¥‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå: ‡∏à‡∏£‡∏¥‡∏á vs. ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå')
                plt.xlabel('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà')
                plt.ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡∏π‡∏ô‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ')
                plt.legend()
                plt.grid(True)
                st.pyplot(fig)

                st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")
                st.dataframe(final_forecast_df[['ds', 'yhat_hybrid']].tail(future_periods))
            else:
                st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost ‡πÑ‡∏î‡πâ: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠, ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ, ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Features ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô.")
                st.write("Current daily_sales_features columns:", daily_sales_features.columns.tolist())
                st.write("Expected xgb_features:", xgb_features_existing)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå: {e}")
            st.exception(e)
    else:
        st.warning("‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡πÅ‡∏ñ‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Prophet ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ")
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå")

# --- NEW: Forecasting by Project Type ---
if not sales_df.empty and 'Project_Type' in sales_df.columns:
    st.subheader("‡∏Å‡∏£‡∏≤‡∏ü‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£")
    project_types_for_selection = ['‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'] + sales_df['Project_Type'].unique().tolist()
    selected_project_type_forecast = st.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå:",
        options=project_types_for_selection
    )

    if selected_project_type_forecast == '‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î':
        # Re-display the overall forecast graph
        st.write("‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        fig = plt.figure(figsize=(12, 6))
        plt.plot(prophet_df['ds'], prophet_df['y'], label='‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á‡∏£‡∏ß‡∏°', color='blue')
        plt.plot(final_forecast_df['ds'], final_forecast_df['yhat_hybrid'], label='‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (Prophet + XGBoost)', color='green', linestyle='--')
        plt.plot(forecast_prophet['ds'], forecast_prophet['yhat'], label='‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (Prophet Baseline)', color='orange', linestyle=':')
        
        forecast_start_date = sales_df['Date'].max()
        plt.axvline(x=forecast_start_date, color='red', linestyle='--', label='‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå', alpha=0.7)

        plt.title('‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏£‡∏¥‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå: ‡∏à‡∏£‡∏¥‡∏á vs. ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó)')
        plt.xlabel('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà')
        plt.ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡∏π‡∏ô‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ')
        plt.legend()
        plt.grid(True)
        st.pyplot(fig)
    else:
        st.write(f"‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: **{selected_project_type_forecast}**")
        
        filtered_sales_df_for_forecast = sales_df[sales_df['Project_Type'] == selected_project_type_forecast].copy()
        
        if not filtered_sales_df_for_forecast.empty and len(filtered_sales_df_for_forecast) > 1:
            prophet_df_filtered = filtered_sales_df_for_forecast.groupby('Date')['Units_Sold'].sum().reset_index()
            prophet_df_filtered.rename(columns={'Date': 'ds', 'Units_Sold': 'y'}, inplace=True)

            try:
                m_filtered = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)
                m_filtered.fit(prophet_df_filtered)
                future_filtered = m_filtered.make_future_dataframe(periods=future_periods)
                forecast_prophet_filtered = m_filtered.predict(future_filtered)
                
                # For simplicity, we are only using Prophet for per-project-type forecast.
                # Adding XGBoost here would require more robust feature engineering per type.
                
                fig = plt.figure(figsize=(12, 6))
                plt.plot(prophet_df_filtered['ds'], prophet_df_filtered['y'], label=f'‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á {selected_project_type_forecast}', color='blue')
                plt.plot(forecast_prophet_filtered['ds'], forecast_prophet_filtered['yhat'], label=f'‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå {selected_project_type_forecast} (Prophet)', color='green', linestyle='--')
                
                forecast_start_date_filtered = filtered_sales_df_for_forecast['Date'].max()
                plt.axvline(x=forecast_start_date_filtered, color='red', linestyle='--', label='‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå', alpha=0.7)

                plt.title(f'‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏£‡∏¥‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå: ‡∏à‡∏£‡∏¥‡∏á vs. ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå ({selected_project_type_forecast})')
                plt.xlabel('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà')
                plt.ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡∏π‡∏ô‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ')
                plt.legend()
                plt.grid(True)
                st.pyplot(fig)

                st.subheader(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {selected_project_type_forecast}")
                st.dataframe(forecast_prophet_filtered[['ds', 'yhat']].tail(future_periods))

            except Exception as e:
                st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ {selected_project_type_forecast} ‡πÑ‡∏î‡πâ: {e}. ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ.")
        else:
            st.info(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ '{selected_project_type_forecast}' ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå.")
else:
    st.info("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ, ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Project Details.")


# --- Additional Sales Insights for Executive ---
st.header("üìà ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç")
if not sales_df.empty:
    st.write("---")
    
    if 'Project_Type' in sales_df.columns:
        sales_by_type = sales_df.groupby('Project_Type')['Sales_Revenue'].sum().sort_values(ascending=False)
        st.write("**‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£:**")
        st.dataframe(sales_by_type)
    else:
        st.warning("‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Project_Type' ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡∏µ‡πâ (‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Project Details).")

    sales_by_project = sales_df.groupby('Project_Name')['Sales_Revenue'].sum().sort_values(ascending=False)
    st.write("**‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏î‡∏µ/‡πÅ‡∏¢‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ):**")
    col_top, col_bottom = st.columns(2)
    with col_top:
        st.write("**Top 5 ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£**")
        st.dataframe(sales_by_project.head(5))
    with col_bottom:
        st.write("**Bottom 5 ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£**")
        st.dataframe(sales_by_project.tail(5))

    if 'Lead_Source' in sales_df.columns:
        sales_by_lead_source = sales_df.groupby('Lead_Source')['Sales_Revenue'].sum().sort_values(ascending=False)
        st.write("**‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á Lead:**")
        st.dataframe(sales_by_lead_source)
    else:
        st.warning("‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Lead_Source' ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡∏µ‡πâ.")

    if 'Promotion_Applied' in sales_df.columns:
        sales_by_promotion = sales_df.groupby('Promotion_Applied')['Sales_Revenue'].sum().sort_values(ascending=False)
        st.write("**‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:**")
        st.dataframe(sales_by_promotion)
    else:
        st.warning("‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Promotion_Applied' ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡∏µ‡πâ.")
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å")


# --- NEW SECTION: Project Details Analysis ---
st.header("üè¢ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£")
if not project_details_df.empty:
    st.write("---") # Divider
    st.subheader("‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£")
    st.dataframe(project_details_df.head())

    if 'Units_Sold_toDate' in project_details_df.columns and 'Proximity_to_BTS_MRT_Km' in project_details_df.columns:
        st.subheader("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å BTS/MRT")
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.scatterplot(data=project_details_df, x='Proximity_to_BTS_MRT_Km', y='Units_Sold_toDate', hue='Project_Type', ax=ax)
        ax.set_title('‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏∞‡∏™‡∏° vs. ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å BTS/MRT')
        ax.set_xlabel('‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å BTS/MRT (‡∏Å‡∏°.)')
        ax.set_ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡∏π‡∏ô‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ (‡∏™‡∏∞‡∏™‡∏°)')
        st.pyplot(fig)
    else:
        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'Units_Sold_toDate' ‡∏´‡∏£‡∏∑‡∏≠ 'Proximity_to_BTS_MRT_Km' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£.")
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£")

# --- NEW SECTION: Marketing Activities Analysis ---
st.header("üì£ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î")
if not marketing_activities_df.empty:
    st.write("---") # Divider
    st.subheader("‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ")
    marketing_summary = marketing_activities_df.groupby('Marketing_Channel').agg(
        Total_Budget=('Budget_Baht', 'sum'),
        Total_Leads=('Leads_Generated', 'sum')
    ).sort_values(by='Total_Budget', ascending=False)
    st.dataframe(marketing_summary)

    if 'Total_Budget' in marketing_summary.columns and 'Total_Leads' in marketing_summary.columns:
        st.subheader("‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î vs. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ (‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á)")
        fig, ax = plt.subplots(figsize=(12, 6))
        
        marketing_summary_plot = marketing_summary.copy()
        
        # Corrected label format for plot function
        marketing_summary_plot.plot(kind='bar', y=['Total_Budget'], ax=ax, width=0.4, position=1, label=['‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏£‡∏ß‡∏° (‡∏ö‡∏≤‡∏ó)'])
        ax2 = ax.twinx()
        marketing_summary_plot.plot(kind='bar', y=['Total_Leads'], ax=ax2, width=0.4, position=0, color='orange', label=['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads ‡∏£‡∏ß‡∏°'])
        
        ax.set_title('‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î vs. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ (‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á)')
        ax.set_xlabel('‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î')
        ax.set_ylabel('‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì (‡∏ö‡∏≤‡∏ó)')
        ax2.set_ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads')
        ax.ticklabel_format(style='plain', axis='y')
        ax2.ticklabel_format(style='plain', axis='y')
        plt.xticks(rotation=45, ha='right')
        
        # Combine legends from both axes
        lines, labels = ax.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        fig.legend(lines + lines2, labels + labels2, loc="upper right", bbox_to_anchor=(0.95, 0.95))

        plt.tight_layout(rect=[0, 0, 0.9, 1])
        st.pyplot(fig)
    else:
        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'Total_Budget' ‡∏´‡∏£‡∏∑‡∏≠ 'Total_Leads' ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î.")
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î")

# --- NEW SECTION: Sales Funnel Analysis ---
st.header("üìä ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Sales Funnel")
if not sales_funnel_df.empty:
    st.write("---") # Divider
    st.subheader("‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° Sales Funnel")
    
    total_leads = len(sales_funnel_df)
    converted_leads = sales_funnel_df[sales_funnel_df['Is_Converted_to_Sale'] == True]
    conversion_rate = (len(converted_leads) / total_leads) * 100 if total_leads > 0 else 0

    st.info(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Lead ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_leads:,.0f} | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Lead ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢: {len(converted_leads):,.0f} | ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ (Conversion Rate): {conversion_rate:.2f}%")

    leads_by_source = sales_funnel_df.groupby('Lead_Source').size().sort_values(ascending=False)
    st.subheader("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads ‡∏ï‡∏≤‡∏°‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤")
    fig, ax = plt.subplots(figsize=(10, 6))
    leads_by_source.plot(kind='bar', ax=ax)
    ax.set_title('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads ‡∏ï‡∏≤‡∏°‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤')
    ax.set_xlabel('‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á Lead')
    ax.set_ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    st.pyplot(fig)
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Sales Funnel")

# --- NEW SECTION: Competitor Analysis ---
st.header("üìä ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á")
if not competitor_df.empty:
    st.write("---") # Divider
    st.subheader("‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á")
    st.dataframe(competitor_df.head())

    st.subheader("‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠ ‡∏ï‡∏£.‡∏°. ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(data=competitor_df.sort_values(by='Avg_Price_Per_SqM', ascending=False), x='Competitor_Project_Name', y='Avg_Price_Per_SqM', ax=ax)
    ax.set_title('‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠ ‡∏ï‡∏£.‡∏°. ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á')
    ax.set_xlabel('‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á')
    ax.set_ylabel('‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠ ‡∏ï‡∏£.‡∏°. (‡∏ö‡∏≤‡∏ó)')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    st.pyplot(fig)
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á")

# --- NEW SECTION: Macroeconomic Data Insights ---
st.header("üìà ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏°‡∏´‡∏†‡∏≤‡∏Ñ")
if not macro_economic_df.empty:
    st.write("---") # Divider
    st.subheader("‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏ü‡πâ‡∏≠")
    fig, ax1 = plt.subplots(figsize=(12, 6))
    ax1.plot(macro_economic_df['Date'], macro_economic_df['Interest_Rate_Percent'], color='blue', label='‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ (%)')
    ax1.set_xlabel('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà')
    ax1.set_ylabel('‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢ (%)', color='blue')
    ax1.tick_params(axis='y', labelcolor='blue')

    ax2 = ax1.twinx()
    ax2.plot(macro_economic_df['Date'], macro_economic_df['Inflation_Rate_Percent'], color='red', label='‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏ü‡πâ‡∏≠ (%)')
    ax2.set_ylabel('‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏ü‡πâ‡∏≠ (%)', color='red')
    ax2.tick_params(axis='y', labelcolor='red')

    fig.tight_layout()
    plt.title('‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏ü‡πâ‡∏≠')
    fig.legend(loc="upper left", bbox_to_anchor=(0.1,0.9))
    st.pyplot(fig)

    st.subheader("‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡πÇ‡∏†‡∏Ñ‡πÅ‡∏•‡∏∞ GDP Growth")
    fig, ax1 = plt.subplots(figsize=(12, 6))
    ax1.plot(macro_economic_df['Date'], macro_economic_df['Consumer_Confidence_Index'], color='green', label='‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡πÇ‡∏†‡∏Ñ')
    ax1.set_xlabel('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà')
    ax1.set_ylabel('‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô', color='green')
    ax1.tick_params(axis='y', labelcolor='green')

    ax2 = ax1.twinx()
    ax2.plot(macro_economic_df['Date'], macro_economic_df['GDP_Growth_Rate_Percent'], color='purple', label='GDP Growth Rate (%)')
    ax2.set_ylabel('GDP Growth Rate (%)', color='purple')
    ax2.tick_params(axis='y', labelcolor='purple')

    fig.tight_layout()
    plt.title('‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡πÇ‡∏†‡∏Ñ‡πÅ‡∏•‡∏∞ GDP Growth Rate')
    fig.legend(loc="upper left", bbox_to_anchor=(0.1,0.9))
    st.pyplot(fig)

else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏°‡∏´‡∏†‡∏≤‡∏Ñ")

# --- Customer Feedback Analysis Section (with Llama 3.1 8B) ---
st.header("üí¨ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ (‡πÇ‡∏î‡∏¢ Llama 3.1 8B)")
if not feedback_df.empty:
    client = ollama.Client(host=ollama_base_url)

    @st.cache_data
    def analyze_sentiment(text):
        if not text: return "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏á)"
        try:
            response = client.chat(
                model=ollama_model_name,
                messages=[
                    {
                        'role': 'user',
                        'content': f"Analyze the sentiment of the following real estate customer feedback as POSITIVE, NEGATIVE, or NEUTRAL, and explain why briefly (in Thai if possible): '{text}'",
                    },
                ],
                options={'temperature': 0.2}
            )
            return response['message']['content']
        except Exception as e:
            st.error(f"Error connecting to Ollama (Sentiment): {e}. Please check URL or server status and model.")
            return "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ"

    @st.cache_data
    def summarize_feedback(text):
        if not text: return "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏á)"
        try:
            response = client.chat(
                model=ollama_model_name,
                messages=[
                    {
                        'role': 'user',
                        'content': f"Summarize the key points of the following real estate customer feedback in one concise sentence (in Thai if possible): '{text}'",
                    },
                ],
                options={'temperature': 0.2}
            )
            return response['message']['content']
        except Exception as e:
            st.error(f"Error connecting to Ollama (Summary): {e}. Please check URL or server status and model.")
            return "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ"

    if st.button("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤"):
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô... ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà"):
            if 'feedback_text' in feedback_df.columns:
                feedback_subset = feedback_df.head(50).copy()
                feedback_subset['feedback_text'] = feedback_subset['feedback_text'].astype(str)

                feedback_subset['sentiment_analysis'] = feedback_subset['feedback_text'].apply(analyze_sentiment)
                feedback_subset['summary'] = feedback_subset['feedback_text'].apply(summarize_feedback)
                
                st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô")
                sentiment_counts = feedback_subset['sentiment_analysis'].apply(lambda x: "POSITIVE" if "POSITIVE" in x.upper() else ("NEGATIVE" if "NEGATIVE" in x.upper() else "NEUTRAL" if "NEUTRAL" in x.upper() else "UNKNOWN")).value_counts()
                
                if not sentiment_counts.empty and len(sentiment_counts) > 1:
                    fig_pie = plt.figure(figsize=(8, 8))
                    plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette("pastel"))
                    plt.title('‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤')
                    st.pyplot(fig_pie)
                else:
                    st.write("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sentiment ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Sentiment ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü.")

                st.subheader("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
                st.dataframe(feedback_subset[['feedback_text', 'sentiment_analysis', 'summary']])
            else:
                st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'feedback_text' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå.")
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤")

# --- Interactive AI Chat (Q&A with Llama 3.1 8B) ---
st.header("ü§ñ ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö AI (Llama 3.1 8B)")
st.write("‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

st.subheader("‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏î‡∏π‡∏™‡∏¥:")

suggested_questions = [
    "‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 30 ‡∏ß‡∏±‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢",
    "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏´‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡πâ‡∏ô",
    "‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡πÉ‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á Leads ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
    "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Lead ‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà",
    "‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠ ‡∏ï‡∏£.‡∏°. ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á‡πÉ‡∏ô‡πÄ‡∏Ç‡∏ï‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà",
    "‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡πÇ‡∏†‡∏Ñ‡∏ó‡∏µ‡πà‡∏•‡∏î‡∏•‡∏á ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï"
]

# Variable to hold the chosen prompt from suggestions
chosen_prompt = None

# Display suggested questions as buttons in columns
cols = st.columns(3)
for i, question in enumerate(suggested_questions):
    with cols[i % 3]: # Distribute buttons into 3 columns
        if st.button(question, key=f"q_suggest_{i}"):
            chosen_prompt = question # Store the chosen question
            # No st.rerun() here yet, we'll handle the prompt processing below

# Or use a selectbox for many questions
selected_question_from_list = st.selectbox(
    "‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£:",
    [""] + suggested_questions,
    key="select_q_from_list"
)
if selected_question_from_list:
    if st.button("‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", key="ask_selected_q"):
        chosen_prompt = selected_question_from_list # Store the chosen question
        # No st.rerun() here yet


# Get user input from chat_input
user_input_prompt = st.chat_input("‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡πÑ‡∏´‡∏°?")

# Determine the actual prompt to process
# Prioritize chosen_prompt from suggestions if available, otherwise use chat_input
actual_prompt = chosen_prompt if chosen_prompt else user_input_prompt

if actual_prompt:
    # Add user message to chat history if it's new (not already added by button logic)
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user" and st.session_state.messages[-1]["content"] == actual_prompt:
        pass
    else:
        st.session_state.messages.append({"role": "user", "content": actual_prompt})

    # Display the user message immediately
    with st.chat_message("user"):
        st.markdown(actual_prompt)

    with st.chat_message("assistant"):
        with st.spinner("AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
            assistant_response = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢, ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI."
            try:
                context_data = ""

                # --- Build context_data based on available DataFrames ---
                # (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
                if not sales_df.empty:
                    total_revenue = sales_df['Sales_Revenue'].sum()
                    total_units = sales_df['Units_Sold'].sum()
                    context_data += (
                        f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢:\n"
                        f"- ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏° (‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ): {total_revenue:,.0f} ‡∏ö‡∏≤‡∏ó\n"
                        f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡∏π‡∏ô‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏°: {total_units:,.0f} ‡∏¢‡∏π‡∏ô‡∏¥‡∏ï\n"
                    )
                    if 'Project_Type' in sales_df.columns and not sales_df['Project_Type'].empty:
                        sales_by_type = sales_df.groupby('Project_Type')['Sales_Revenue'].sum().to_string()
                        context_data += f"- ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£:\n{sales_by_type}\n"
                    if 'Lead_Source' in sales_df.columns and not sales_df['Lead_Source'].empty:
                        top_lead_source = sales_df.groupby('Lead_Source')['Units_Sold'].sum().idxmax()
                        context_data += f"- ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á Lead ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {top_lead_source}\n"
                    context_data += "\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô:\n" + sales_df.tail(5).to_string()

                if not feedback_df.empty and 'summary' in feedback_df.columns and not feedback_df['summary'].empty:
                    context_data += "\n\n‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô:\n"
                    context_data += feedback_df['summary'].dropna().sample(min(5, len(feedback_df)), random_state=42).to_string(index=False)

                if not project_details_df.empty:
                    context_data += "\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£:\n"
                    context_data += project_details_df.describe(include='all').to_string()
                    context_data += f"\n- ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(project_details_df)} ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£\n"
                    context_data += f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡∏π‡∏ô‡∏¥‡∏ï‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£: {project_details_df['Total_Units'].sum():,.0f} ‡∏¢‡∏π‡∏ô‡∏¥‡∏ï\n"
                    
                if not marketing_activities_df.empty:
                    total_marketing_budget = marketing_activities_df['Budget_Baht'].sum()
                    total_leads_generated = marketing_activities_df['Leads_Generated'].sum()
                    if 'Marketing_Channel' in marketing_activities_df.columns and not marketing_activities_df['Marketing_Channel'].empty:
                        top_marketing_channel = marketing_activities_df.groupby('Marketing_Channel')['Leads_Generated'].sum().idxmax()
                        context_data += f"- ‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á Leads ‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {top_marketing_channel}\n"
                    context_data += (
                        f"\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î:\n"
                        f"- ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡∏£‡∏ß‡∏°: {total_marketing_budget:,.0f} ‡∏ö‡∏≤‡∏ó\n"
                        f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏°: {total_leads_generated:,.0f} Leads\n"
                    )

                if not sales_funnel_df.empty:
                    total_leads_funnel = len(sales_funnel_df)
                    converted_leads_funnel = sales_funnel_df[sales_funnel_df['Is_Converted_to_Sale'] == True]
                    conversion_rate_funnel = (len(converted_leads_funnel) / total_leads_funnel) * 100 if total_leads_funnel > 0 else 0
                    context_data += (
                        f"\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sales Funnel:\n"
                        f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Leads ‡πÉ‡∏ô Funnel: {total_leads_funnel:,.0f}\n"
                        f"- ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏à‡∏≤‡∏Å Funnel: {conversion_rate_funnel:.2f}%\n"
                    )
                    
                if not competitor_df.empty:
                    avg_comp_price = competitor_df['Avg_Price_Per_SqM'].mean()
                    context_data += (
                        f"\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á:\n"
                        f"- ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠ ‡∏ï‡∏£.‡∏°. ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á: {avg_comp_price:,.0f} ‡∏ö‡∏≤‡∏ó\n"
                        f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°: {len(competitor_df)} ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£\n"
                    )

                if not macro_economic_df.empty:
                    context_data += "\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏°‡∏´‡∏†‡∏≤‡∏Ñ (‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î):\n"
                    context_data += macro_economic_df.tail(1).to_string()

                llm_prompt = (
                    f"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏£‡∏¥‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå "
                    f"‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö "
                    f"‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏Ø "
                    f"‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:\n\n"
                    f"**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:** {actual_prompt}\n\n"
                    f"**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:**\n{context_data}\n\n"
                    f"**‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:**"
                )

                if ai_provider == "Ollama (Local Llama)":
                    if ollama_base_url and ollama_model_name:
                        client_ollama = ollama.Client(host=ollama_base_url)
                        response = client_ollama.chat(
                            model=ollama_model_name,
                            messages=[
                                {"role": "system", "content": "You are a helpful real estate sales data analysis assistant for a large real estate company in Thailand. Provide insights and recommendations for executives based on provided data."},
                                {"role": "user", "content": llm_prompt},
                            ],
                            options={'temperature': 0.7}
                        )
                        assistant_response = response['message']['content']
                    else:
                        st.warning("‡πÇ‡∏õ‡∏£‡∏î‡∏Å‡∏≥‡∏´‡∏ô‡∏î Ollama Server URL ‡πÅ‡∏•‡∏∞ Model Name ‡πÉ‡∏ô Sidebar.")
                        assistant_response = "Ollama ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤."

                elif ai_provider == "OpenAI (GPT)":
                    if openai_api_key and openai_model_name:
                        client_openai = openai.OpenAI(api_key=openai_api_key)
                        response = client_openai.chat.completions.create(
                            model=openai_model_name,
                            messages=[
                                {"role": "system", "content": "You are a helpful real estate sales data analysis assistant for a large real estate company in Thailand. Provide insights and recommendations for executives based on provided data."},
                                {"role": "user", "content": llm_prompt},
                            ],
                            temperature=0.7,
                        )
                        assistant_response = response.choices[0].message.content
                    else:
                        st.warning("‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏™‡πà OpenAI API Key ‡πÅ‡∏•‡∏∞ Model Name ‡πÉ‡∏ô Sidebar.")
                        assistant_response = "OpenAI ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤."

                elif ai_provider == "Google AI (Gemini)":
                    if google_api_key and google_model_name:
                        from google.generativeai import configure
                        configure(api_key=google_api_key)
                        model_gemini = GenerativeModel(
                            model_name=google_model_name,
                            # Adjust safety settings if needed for your use case
                            safety_settings={
                                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                            }
                        )
                        # For Gemini, system instructions are not directly supported in the same way as OpenAI/Ollama in chat.
                        # You can put the system prompt as the first message or integrate it into the user prompt.
                        # Here, we integrate it into the user prompt for simplicity.
                        full_gemini_prompt = (
                            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏£‡∏¥‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏Ø\n\n" + llm_prompt
                        )
                        response = model_gemini.generate_content(
                            full_gemini_prompt,
                            generation_config={"temperature": 0.7}
                        )
                        assistant_response = response.text
                    else:
                        st.warning("‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏™‡πà Google AI API Key ‡πÅ‡∏•‡∏∞ Model Name ‡πÉ‡∏ô Sidebar.")
                        assistant_response = "Google AI ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤."

                st.markdown(assistant_response)
                st.session_state.messages.append({"role": "assistant", "content": assistant_response})

            except openai.APIError as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏à‡∏≤‡∏Å OpenAI API: {e}. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£.")
                st.session_state.messages.append({"role": "assistant", "content": f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞, ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏à‡∏≤‡∏Å OpenAI: {e}"})
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ AI: {e}. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠ Server.")
                st.session_state.messages.append({"role": "assistant", "content": f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞, ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö AI ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}"})

    st.rerun()

    # Always rerun if there's an actual_prompt processed
    # This ensures the chat input field clears and the new message is displayed
    st.rerun() # <<< ‡πÄ‡∏û‡∏¥‡πà‡∏° st.rerun() ‡πÑ‡∏ß‡πâ‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á block ‡∏ô‡∏µ‡πâ